{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Oday ziq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvIhjE2ersXZ"
      },
      "source": [
        "Step 1: Load and Preprocess CIFAR-10 Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLSsbMEBqYAJ",
        "outputId": "5ff98b58-7188-4170-904c-61bfbe5feff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:18<00:00, 9122852.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=32, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeSWUT61H5ly"
      },
      "source": [
        "Define the transform to normalize the data\n",
        "Resize images to 224x224 (required for VGG16 and AlexNet), convert to tensor, and normalize\n",
        "Download and load the training data\n",
        "The CIFAR-10 training dataset is downloaded and loaded with defined transformations Download and load the test data The CIFAR-10 test dataset is downloaded and loaded with defined transformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZT5TEs6ru_j"
      },
      "source": [
        "Step 2: Load Pretrained Models (AlexNet and VGG16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-ZT3_YKr6Uw",
        "outputId": "d9aeca7f-8c4a-4d0a-ced4-dee836f2df1e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 166MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:03<00:00, 173MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "alexnet = models.alexnet(pretrained=True)\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "\n",
        "alexnet.classifier[6] = nn.Linear(alexnet.classifier[6].in_features, 10)\n",
        "vgg16.classifier[6] = nn.Linear(vgg16.classifier[6].in_features, 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCLge_7sIhHb"
      },
      "source": [
        "Load pretrained AlexNet and VGG16 models These models are pre-trained on the ImageNet dataset Modify the final layer for CIFAR-10 (10 classes) The original classification layer is replaced with a new layer for 10 classes (CIFAR-10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RI_4SlXuvN4"
      },
      "source": [
        "Step 3: Set Up Finetuning and ConvNet as Fixed Feature Extractor Approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY_Q95tmItGW"
      },
      "source": [
        "Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esF0689vutCw",
        "outputId": "870cfc7e-1442-48e9-8f82-9147fd89cb5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3], Loss: 0.6196\n",
            "Epoch [2/3], Loss: 0.3814\n",
            "Epoch [3/3], Loss: 0.2969\n",
            "Accuracy: 89.02%\n",
            "Epoch [1/3], Loss: 0.4477\n",
            "Epoch [2/3], Loss: 0.2198\n",
            "Epoch [3/3], Loss: 0.1432\n",
            "Accuracy: 92.76%\n"
          ]
        }
      ],
      "source": [
        "def train_model(model, trainloader, criterion, optimizer, num_epochs=3):\n",
        "    # Training loop for the model\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set the model to training mode\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in trainloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to the appropriate device\n",
        "            optimizer.zero_grad()  # Zero the parameter gradients\n",
        "            outputs = model(inputs)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Compute loss\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Update weights\n",
        "            running_loss += loss.item()\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}')  # Print loss for each epoch\n",
        "\n",
        "def evaluate_model(model, testloader):\n",
        "    # Evaluation loop for the model\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in testloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to the appropriate device\n",
        "            outputs = model(inputs)  # Forward pass\n",
        "            _, predicted = torch.max(outputs.data, 1)  # Get the predicted class\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    print(f'Accuracy: {100 * correct / total:.2f}%')  # Print the accuracy\n",
        "\n",
        "# Set up device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
        "alexnet.to(device)  # Move AlexNet to the device\n",
        "vgg16.to(device)  # Move VGG16 to the device\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()  # Cross-entropy loss for classification\n",
        "optimizer_alexnet = torch.optim.SGD(alexnet.parameters(), lr=0.001, momentum=0.9)  # Optimizer for AlexNet\n",
        "optimizer_vgg16 = torch.optim.SGD(vgg16.parameters(), lr=0.001, momentum=0.9)  # Optimizer for VGG16\n",
        "\n",
        "# Train and evaluate AlexNet\n",
        "train_model(alexnet, trainloader, criterion, optimizer_alexnet, num_epochs=3)  # Train AlexNet\n",
        "evaluate_model(alexnet, testloader)  # Evaluate AlexNet\n",
        "\n",
        "# Train and evaluate VGG16\n",
        "train_model(vgg16, trainloader, criterion, optimizer_vgg16, num_epochs=3)  # Train VGG16\n",
        "evaluate_model(vgg16, testloader)  # Evaluate VGG16\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ8U9C1BIwKr"
      },
      "source": [
        "ConvNet as Fixed Feature Extractor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-dGmQt9Ixcv",
        "outputId": "4ca18314-74de-470b-da23-5e867769356e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/3], Loss: 0.2115\n",
            "Epoch [2/3], Loss: 0.1977\n",
            "Epoch [3/3], Loss: 0.1936\n",
            "Accuracy: 90.62%\n",
            "Epoch [1/3], Loss: 0.0664\n",
            "Epoch [2/3], Loss: 0.0601\n",
            "Epoch [3/3], Loss: 0.0585\n",
            "Accuracy: 93.47%\n"
          ]
        }
      ],
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    # Freeze parameters for feature extraction\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "# Freeze all layers except the final one for AlexNet and VGG16\n",
        "set_parameter_requires_grad(alexnet, feature_extracting=True)\n",
        "set_parameter_requires_grad(vgg16, feature_extracting=True)\n",
        "\n",
        "# Ensure the last layer requires gradients\n",
        "# Remember to set requires_grad to True for all layers you want to train.\n",
        "for param in alexnet.classifier[6].parameters():\n",
        "    param.requires_grad = True\n",
        "for param in vgg16.classifier[6].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Redefine the optimizer to only train the final layer\n",
        "optimizer_alexnet = torch.optim.SGD(alexnet.classifier[6].parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer_vgg16 = torch.optim.SGD(vgg16.classifier[6].parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Train and evaluate AlexNet as feature extractor\n",
        "train_model(alexnet, trainloader, criterion, optimizer_alexnet, num_epochs=3)  # Train AlexNet as a fixed feature extractor\n",
        "evaluate_model(alexnet, testloader)  # Evaluate AlexNet\n",
        "\n",
        "# Train and evaluate VGG16 as feature extractor\n",
        "train_model(vgg16, trainloader, criterion, optimizer_vgg16, num_epochs=3)  # Train VGG16 as a fixed feature extractor\n",
        "evaluate_model(vgg16, testloader)  # Evaluate VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNiB5MGFq-91"
      },
      "source": [
        "In this case study, we applied transfer learning using two popular networks, AlexNet and VGG16, to classify images on the CIFAR-10 dataset. We tested two setups: finetuning and using the ConvNet as a fixed feature extractor. The finetuning approach involves updating all the pretrained weights, including those of the newly added classification layer, while the fixed feature extractor approach involves freezing the weights of all layers except the final fully connected layer, which is trained from scratch.\n",
        "\n",
        "Based on the results from the training and evaluation of AlexNet and VGG16 using the two setups, several comparisons and observations can be made. For the finetuning setup, AlexNet's loss decreased from 0.6196 in the first epoch to 0.2969 in the third epoch, resulting in a final test accuracy of 89.02%. In contrast, VGG16's loss decreased from 0.4477 to 0.1432 over the same period, achieving a final test accuracy of 92.76%. When using the ConvNet as a fixed feature extractor, AlexNet's loss decreased from 0.2115 to 0.1936, with a final test accuracy of 90.62%. VGG16, on the other hand, showed a loss decrease from 0.0664 to 0.0585, attaining the highest test accuracy of 93.47%.\n",
        "\n",
        "These results reveal that both models exhibit higher accuracy when employed as fixed feature extractors compared to finetuning. This indicates that the features learned from the pre-trained models are robust and highly effective for the CIFAR-10 classification task, requiring minimal modifications to the network. VGG16 consistently outperforms AlexNet in both setups, highlighting that deeper networks like VGG16 can capture more complex features, leading to better performance in tasks involving detailed image patterns.\n",
        "\n",
        "Regarding loss reduction, the finetuning approach shows a more significant decrease in both models, which suggests that more layers are adjusted to better fit the CIFAR-10 dataset. However, the accuracy improvement is not as substantial, potentially due to overfitting or the initial pre-trained weights being quite suitable for the task already. Conversely, using the ConvNet as a fixed feature extractor results in lower initial loss values and a steady but less pronounced decrease, indicating that the pre-trained features are already well-suited for the classification task and require minimal fine-tuning.\n",
        "\n",
        "In conclusion, VGG16 as a fixed feature extractor achieved the highest accuracy of 93.47%, demonstrating the effectiveness of leveraging rich feature representations learned from large datasets like ImageNet for similar tasks. AlexNet as a fixed feature extractor also outperformed its finetuning counterpart, showcasing the robustness of pre-trained features. The finetuning approach did not significantly enhance accuracy over the fixed feature extractor method, suggesting that the pre-trained weights are highly effective for CIFAR-10. These findings underscore the power of transfer learning, particularly with well-pretrained models and deep architectures like VGG16, and indicate that using a model as a fixed feature extractor can provide excellent results with reduced computational cost and complexity."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
